{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pathlib as pl\n",
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# ensure tensorflow doesn't use GPU or too many CPUs\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "tf.config.threading.set_intra_op_parallelism_threads(5)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(5)\n",
    "import candas\n",
    "from candas.learn import ParameterSet, parray\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Best Points\n",
    "\n",
    "This notebook finds the best point on each surfce for both the penalized and unpenalized optimisation cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First load and format the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "log_transform=False\n",
    "\n",
    "path = pl.Path(os.getcwd()).parent\n",
    "ps_df = pd.read_pickle(path / 'data' / 'ADVI_ParameterSets_220528.pkl')\n",
    "ps_df = ps_df[(ps_df.lg10_Copies == 8)]\n",
    "ps_df = ps_df.drop(ps_df[ps_df['Experiment'].str.contains(\"JG073A\")].index)\n",
    "ps = ParameterSet.from_wide(ps_df)\n",
    "if not log_transform:\n",
    "    ps.stdzr.transforms['r'] = [candas.utils.skip, candas.utils.skip]\n",
    "    ps.stdzr.transforms['m'] = [candas.utils.skip, candas.utils.skip]\n",
    "    for param in ['r', 'm']:\n",
    "        ps.stdzr[param] = {\n",
    "            'μ': ps.data.loc[(ps.data['Parameter'] == param) & (ps.data['Metric'] == 'mean'), 'Value'].mean(),\n",
    "            'σ': ps.data.loc[(ps.data['Parameter'] == param) & (ps.data['Metric'] == 'mean'), 'Value'].std()}\n",
    "else:\n",
    "    pass\n",
    "ps.data['EvaGreen'] = ((ps.data['Reporter'] == \"EVAGREEN\") | (ps.data['Reporter'] == \"SYBR\"))\n",
    "ps.data.loc[ps.data['EvaGreen'] == True, 'EvaGreen'] = 'EvaGreen'\n",
    "ps.data.loc[ps.data['EvaGreen'] == False, 'EvaGreen'] = 'Probe'\n",
    "ps.data['PrimerPairReporter'] = ps.data[['PrimerPair', 'EvaGreen']].agg('-'.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for param in ['r', 'm']:\n",
    "    df = ps.data[(ps.data['Parameter'] == param) & (ps.data['Metric'] == 'mean')]\n",
    "    df[param] = df['Value']\n",
    "    df = df[['PrimerPairReporter', 'BP', 'GC', 'Experiment', 'Well', 'Target', 'Copies', param]]\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.merge(*dfs, on=['PrimerPairReporter', 'BP', 'GC', 'Experiment', 'Well', 'Target', 'Copies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Experiment', 'Well', 'Target', 'Copies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.groupby(['PrimerPairReporter', 'BP', 'GC']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_parray = parray(**{'r': df['r'], 'm':df['m']}, stdzr=ps.stdzr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['stzd r'] = param_parray['r'].z.values()\n",
    "df['stzd m'] = param_parray['m'].z.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = pl.Path(os.getcwd()).parent\n",
    "with open(path / 'data' / 'JG067 sequence targets.csv', \"rb\") as file:\n",
    "    targets = pd.read_csv(file)\n",
    "targets['PrimerPair'] = targets[['FPrimer', 'RPrimer']].agg('-'.join, axis=1)\n",
    "targets['EvaGreen'] = ((targets['-Strand Label'] == \"None\") & (targets['+Strand Label'] == \"None\"))\n",
    "targets.loc[targets['EvaGreen'] == True, 'EvaGreen'] = 'EvaGreen'\n",
    "targets.loc[targets['EvaGreen'] == False, 'EvaGreen'] = 'Probe'\n",
    "targets['PrimerPairReporter'] = targets[['PrimerPair', 'EvaGreen']].agg('-'.join, axis=1)\n",
    "targets = targets.drop_duplicates(subset=['PrimerPairReporter'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "r_targ_parray = parray(**{'r': targets['Target Rate']}, stdzr=ps.stdzr)\n",
    "\n",
    "targets['Target Rate z'] = r_targ_parray.z.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for ppr in targets['PrimerPairReporter'].unique():\n",
    "    df.loc[df['PrimerPairReporter'] == ppr, 'target r'] = targets.loc[targets['PrimerPairReporter'] == ppr,\n",
    "                                                                      'Target Rate'].to_numpy()[0]\n",
    "    df.loc[df['PrimerPairReporter'] == ppr, 'target r z'] = targets.loc[targets['PrimerPairReporter'] == ppr,\n",
    "                                                                      'Target Rate z'].to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['target m'] = 1e-2\n",
    "\n",
    "m_targ_parray = parray(**{'m': 1e-2}, stdzr=ps.stdzr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['target m z'] = m_targ_parray.z.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Find the best points for the unconstrained data_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from Code.expected_improvements import ExpectedImprovement\n",
    "\n",
    "ei = ExpectedImprovement(['r'])\n",
    "df = ei.get_error_from_optimization_target(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(by='error from optimization target z')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_df = df.drop_duplicates(subset=['PrimerPairReporter'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for ppr in best_df['PrimerPairReporter']:\n",
    "    min_df = df[df['PrimerPairReporter']== ppr]['error from optimization target z'].min()\n",
    "    best = best_df[best_df['PrimerPairReporter']==ppr]['error from optimization target z'].to_numpy()[0]\n",
    "    assert min_df == best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = pl.Path(os.getcwd()).parent / 'data'\n",
    "best_df.to_csv(path / 'best_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And for Penalized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from Code.expected_improvements import ExpectedImprovementPenalized\n",
    "\n",
    "ei = ExpectedImprovementPenalized(['r', 'm'])\n",
    "df = ei.get_error_from_optimization_target(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(by='error from optimization target z')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_df = df.drop_duplicates(subset=['PrimerPairReporter'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for ppr in best_df['PrimerPairReporter']:\n",
    "    min_df = df[df['PrimerPairReporter']== ppr]['error from optimization target z'].min()\n",
    "    best = best_df[best_df['PrimerPairReporter']==ppr]['error from optimization target z'].to_numpy()[0]\n",
    "    assert min_df == best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_df.to_csv(path /'best_df_penalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
