{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pathlib as pl\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "# from scipy.special import logit, expit\n",
    "# from scipy.stats import norm, lognorm, chi2, ncx2, rv_continuous, multivariate_normal\n",
    "from uncertainties import unumpy as unp\n",
    "from collections import namedtuple\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Summary\n",
    "\n",
    "In this notebook we check which surfaces are in the targets and how many unique locations there are on each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      True\n",
      "1      True\n",
      "2     False\n",
      "3     False\n",
      "4     False\n",
      "5      True\n",
      "6     False\n",
      "7      True\n",
      "8      True\n",
      "9      True\n",
      "10     True\n",
      "11    False\n",
      "12    False\n",
      "13     True\n",
      "14     True\n",
      "15    False\n",
      "16     True\n",
      "17    False\n",
      "18     True\n",
      "19    False\n",
      "20     True\n",
      "21     True\n",
      "22    False\n",
      "23    False\n",
      "Name: EvaGreen, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "path = pl.Path(os.getcwd())\n",
    "with open(path / 'data' / 'JG067 sequence targets.csv', \"rb\") as file:\n",
    "    targets = pd.read_csv(file)\n",
    "# print(targets.dtypes)\n",
    "targets = targets.astype({'-Strand Label': str, '+Strand Label': str})\n",
    "targets['PrimerPair'] = targets[['FPrimer', 'RPrimer']].agg('-'.join, axis=1)\n",
    "# print(targets.dtypes)\n",
    "targets['EvaGreen'] = ((targets['-Strand Label'] == \"nan\") & (targets['+Strand Label'] == \"nan\"))\n",
    "print(targets['EvaGreen'])\n",
    "targets.loc[targets['EvaGreen'] == True, 'EvaGreen'] = 'EvaGreen'\n",
    "targets.loc[targets['EvaGreen'] == False, 'EvaGreen'] = 'Probe'\n",
    "targets['PrimerPairReporter'] = targets[['PrimerPair', 'EvaGreen']].agg('-'.join, axis=1)\n",
    "targets = targets.drop_duplicates(subset=['PrimerPairReporter'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0  Sequence Name  Target Rate FPrimer RPrimer -Strand Label +Strand Label  Min BP       CAN Name                          CAN UUID    PrimerPair  EvaGreen     PrimerPairReporter\n",
      "0            0  S067_8a718d_α        0.902   FP001  RP001x           nan           nan      10  Penalized XOR  8a718d80064949059a599ea046a959c8  FP001-RP001x  EvaGreen  FP001-RP001x-EvaGreen\n",
      "1            1  S067_8a718d_β        0.902   FP002  RP002x           nan           nan      10  Penalized XOR  8a718d80064949059a599ea046a959c8  FP002-RP002x  EvaGreen  FP002-RP002x-EvaGreen\n",
      "2            2  S067_8a718d_a        0.866   FP005   FP001           nan            L0      40  Penalized XOR  8a718d80064949059a599ea046a959c8   FP005-FP001     Probe      FP005-FP001-Probe\n",
      "3            3  S067_8a718d_b        0.951  RP001x   FP002            L1            L1      70  Penalized XOR  8a718d80064949059a599ea046a959c8  RP001x-FP002     Probe     RP001x-FP002-Probe\n",
      "4            4  S067_8a718d_c        0.866  RP002x   FP005            L0           nan      40  Penalized XOR  8a718d80064949059a599ea046a959c8  RP002x-FP005     Probe     RP002x-FP005-Probe\n",
      "5            5  S067_8a718d_d        0.653   FP005   FP004           nan           nan      10  Penalized XOR  8a718d80064949059a599ea046a959c8   FP005-FP004  EvaGreen   FP005-FP004-EvaGreen\n",
      "6            6  S067_8a718d_e        0.758   FP004   RP004            L1           nan      40  Penalized XOR  8a718d80064949059a599ea046a959c8   FP004-RP004     Probe      FP004-RP004-Probe\n",
      "8            8  S067_b12a22_β        0.952  RP002x   FP002           nan           nan      10  Penalized AND  b12a2207d5394580967106cb2dc107ce  RP002x-FP002  EvaGreen  RP002x-FP002-EvaGreen\n",
      "9            9  S067_b12a22_a        1.050   FP001   RP004           nan           nan      10  Penalized AND  b12a2207d5394580967106cb2dc107ce   FP001-RP004  EvaGreen   FP001-RP004-EvaGreen\n",
      "10          10  S067_b12a22_b        1.050   FP002   RP004           nan           nan      10  Penalized AND  b12a2207d5394580967106cb2dc107ce   FP002-RP004  EvaGreen   FP002-RP004-EvaGreen\n",
      "12          12  S067_b12a22_d        0.486   FP004   FP005            L0           nan      40  Penalized AND  b12a2207d5394580967106cb2dc107ce   FP004-FP005     Probe      FP004-FP005-Probe\n",
      "15          15  S067_0d89c8_a        0.806  RP008x   FP005           nan            L0      40  Penalized cOR  0d89c8bdccff4d17ae5d4e49a79d0e76  RP008x-FP005     Probe     RP008x-FP005-Probe\n",
      "16          16  S067_0d89c8_b        0.963   FP005   FP001           nan           nan      10  Penalized cOR  0d89c8bdccff4d17ae5d4e49a79d0e76   FP005-FP001  EvaGreen   FP005-FP001-EvaGreen\n",
      "18          18  S067_0d89c8_d        0.963  RP002x   FP004           nan           nan      10  Penalized cOR  0d89c8bdccff4d17ae5d4e49a79d0e76  RP002x-FP004  EvaGreen  RP002x-FP004-EvaGreen\n",
      "20          20  S067_76f36b_α        0.912  RP008x   FP001           nan           nan      10  Penalized uOR  76f36b20221d401389ffdea981307165  RP008x-FP001  EvaGreen  RP008x-FP001-EvaGreen\n",
      "22          22  S067_76f36b_a        1.030   FP001  RP001x            L1           nan      40  Penalized uOR  76f36b20221d401389ffdea981307165  FP001-RP001x     Probe     FP001-RP001x-Probe\n"
     ]
    }
   ],
   "source": [
    "print(targets.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(x):\n",
    "    return x\n",
    "def expit(x):\n",
    "    return x\n",
    "def skip(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "class Standardizer(dict):\n",
    "    r\"\"\"Container for dict of mean (μ) and standard deviation (σ) for every parameter.\n",
    "\n",
    "    :class:`Standardizer` objects allow transformation and normalization of datasets. The main methods are :meth:`stdz`,\n",
    "    which attempts to coerce the values of a given variable to a standard normal distribution (`z-scores`), and its\n",
    "    complement :meth:`unstdz`. The steps are\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{\\text{data}} \\rightarrow \\text{transform} \\rightarrow \\text{mean-center} \\rightarrow \\text{scale}\n",
    "        \\rightarrow \\mathbf{\\text{zdata}}\n",
    "\n",
    "    For example, reaction `rate` must clearly be strictly positive, so we use a `log` transformation so that it behaves\n",
    "    as a normally-distributed random variable. We then mean-center and scale this transformed value to obtain `z-scores`\n",
    "    indicating how similar a given estimate is to all the other estimates we've observed. `Standardizer` stores the\n",
    "    transforms and population mean and standard deviation for every parameter, allowing us to convert back and forth\n",
    "    between natural space (:math:`rate`), transformed space (:math:`\\text{ln}\\; rate`), and standardized space\n",
    "    (:math:`\\left( \\text{ln}\\; rate  - \\mu_{\\text{ln}\\; rate} \\right)/\\sigma_{\\text{ln}\\; rate}`).\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    :class:`Standardizer` is just a `dictionary <https://docs.python.org/3/tutorial/datastructures.html#dictionaries>`_\n",
    "    with some extra methods and defaults, so standard dictionary methods like :meth:`dict.update` still work.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Standardizer: Make required_parameters and required_descriptors optional definition at init\n",
    "    _required_parameters = ['τ', 'ρ', 'r', 'K', 'm', 'lg10_Copies', 'BP', 'GC']\n",
    "    _required_descriptors = ['Parameter', 'lg10_Copies', 'BP', 'GC']\n",
    "\n",
    "    # TODO: Standardizer: make `defaults` optional definition at init\n",
    "    defaults = {\n",
    "        'ρ': {'μ': -1.056, 'σ': 0.398},\n",
    "        'τ': {'μ': 3.34, 'σ': 0.1501},\n",
    "        'K': {'μ': -0.0368, 'σ': 0.351},\n",
    "        'm': {'μ': -5.30, 'σ': 0.582},\n",
    "        'offset': {'μ': 0.214, 'σ': 0.0725},\n",
    "        'lg10_Copies': {'μ': 5, 'σ': 2},\n",
    "        'BP': {'μ': 4.48, 'σ': 0.75},\n",
    "        'GC': {'μ': -0.282, 'σ': 1},\n",
    "        'r': {'μ': -0.307, 'σ': 0.158},\n",
    "        'F0_lg': {'μ': -0.762, 'σ': 1.258},\n",
    "        'bkg_F': {'μ': 0.200, 'σ': 0.0580},\n",
    "        'bkg_Cycle': {'μ': 38.2, 'σ': 23.0}\n",
    "    }\n",
    "\n",
    "    # TODO: Standardizer: make `transforms` and `pymc_transforms` definable via string options\n",
    "    # TODO: Standardizer: make transform suggestions based on provided data? e.g., all>0 -> log/exp\n",
    "    transforms = {\n",
    "        'r': [np.log, np.exp],\n",
    "        'ρ': [logit, expit],\n",
    "        'τ': [np.log, np.exp],\n",
    "        'τ_': [np.log, np.exp],\n",
    "        'K': [np.log, np.exp],\n",
    "        'm': [np.log, np.exp],\n",
    "        'offset': [skip, skip],\n",
    "        'lg10_Copies': [skip, skip],\n",
    "        'BP': [np.log, np.exp],\n",
    "        'GC': [logit, expit]\n",
    "    }\n",
    "\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.validate(kwargs)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def validate(cls, dct: dict):\n",
    "        \"\"\"Ensures provided dictionary has all required attributes\"\"\"\n",
    "        assert_is_subset('Parameters', cls._required_parameters, dct.keys())\n",
    "\n",
    "    @classmethod\n",
    "    def default(cls):\n",
    "        \"\"\"Initializes Standardizer with default values\"\"\"\n",
    "        return cls(**cls.defaults)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Revert to defaults\"\"\"\n",
    "        self.update(**self.defaults)\n",
    "        for k in self.keys():\n",
    "            if k not in self.defaults.keys():\n",
    "                del self[k]\n",
    "        return self\n",
    "\n",
    "    def save(self, filename: str):\n",
    "        \"\"\"Save to pickle file\"\"\"\n",
    "        with open(filename, 'wb') as buff:\n",
    "            pickle.dump(self, buff)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filename: str):\n",
    "        \"\"\"Load from pickle file\"\"\"\n",
    "        with open(filename, 'rb') as buff:\n",
    "            dct = pickle.load(buff)\n",
    "        return cls(**dct)\n",
    "\n",
    "    @classmethod\n",
    "    def from_DataFrame(cls, df: pd.DataFrame):\n",
    "        \"\"\"Construct from DataFrame\"\"\"\n",
    "        assert_in('\"Parameter\"', 'Parameter', df.columns)\n",
    "        if 'Metric' in df.columns:\n",
    "            if 'mean' in df['Metric'].unique():\n",
    "                df = df[df['Metric'] == 'mean']\n",
    "            else:\n",
    "                raise ValueError('If DataFrame contains column \"Metric\", \"means\" must be present in that column')\n",
    "        dct = (df\n",
    "               .groupby('Parameter')\n",
    "               .apply(cls.transform_series)\n",
    "               .groupby('Parameter')\n",
    "               .agg([np.mean, np.std])\n",
    "               .rename(columns={\"mean\": \"μ\", \"std\": \"σ\"})\n",
    "               .T\n",
    "               .to_dict()\n",
    "               )\n",
    "        return cls(**{**cls.defaults, **dct})\n",
    "\n",
    "    @classmethod\n",
    "    def transform(cls, name: str, x: float, lg10_Copies=5., pymc3=False) -> float:\n",
    "        \"\"\"Apply appropriate forward transformation to parameter\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: float\n",
    "            Value to be transformed\n",
    "        name: str\n",
    "            Name of parameter\n",
    "        lg10_Copies: float, default 5.\n",
    "            Corresponding log10 concentration; only necessary for τ\n",
    "        pymc3: bool, optional\n",
    "            Whether to use pymc3's transforms\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "        \"\"\"\n",
    "        _transforms = cls.transforms if not pymc3 else cls.pymc_transforms\n",
    "        ftransform = _transforms.get(name, [skip, skip])[0]\n",
    "        if name == 'τ':\n",
    "            assert lg10_Copies is not None, 'Concentration must be supplied to transform τ'\n",
    "            x = x + np.log2(10) * (lg10_Copies - 5)\n",
    "        return ftransform(x)\n",
    "\n",
    "    @classmethod\n",
    "    def untransform(cls, name: str, x: float, lg10_Copies=5., pymc3=False) -> float:\n",
    "        \"\"\"Apply appropriate reverse transformation to parameter\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: float\n",
    "            Value to be transformed\n",
    "        name: str\n",
    "            Name of parameter\n",
    "        lg10_Copies: float, default 5.\n",
    "            Corresponding log10 concentration; only necessary for τ\n",
    "        pymc3: bool, optional\n",
    "            Whether to use pymc3's transforms\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "        \"\"\"\n",
    "        _transforms = cls.transforms if not pymc3 else cls.pymc_transforms\n",
    "        rtransform = _transforms.get(name, [skip, skip])[1]\n",
    "        x_ = rtransform(x)\n",
    "        if name == 'τ':\n",
    "            assert lg10_Copies is not None, 'Concentration must be supplied to transform τ'\n",
    "            x_ = x_ - np.log2(10) * (lg10_Copies - 5)\n",
    "        return x_\n",
    "\n",
    "    @classmethod\n",
    "    def transform_series(cls, series: pd.Series, val_column='Value') -> float:\n",
    "        \"\"\"Apply appropriate transform to parameter in series\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        series: pd.Series\n",
    "            Series containing value to be transformed. Series.name must be the name of the parameter and series must\n",
    "             also contain a 'lg10_Copies' attribute.\n",
    "        val_column: str, default 'Value'\n",
    "            Name of series column containing value to be transformed.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            float\n",
    "        \"\"\"\n",
    "        assert series.name is not None\n",
    "        return cls.transform(str(series.name), series[val_column], series.lg10_Copies)\n",
    "\n",
    "    def stdz(self, name: str, x: float, lg10_Copies=5., pymc3=False) -> float:\n",
    "        \"\"\"Transforms, mean-centers, and scales parameter\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: float\n",
    "        name: str\n",
    "            Name of parameter\n",
    "        lg10_Copies: float, default 5.\n",
    "            Corresponding log10 concentration; only necessary for τ\n",
    "        pymc3: bool, optional\n",
    "            Whether to use pymc3's transforms\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "        \"\"\"\n",
    "        x_ = self.transform(name, x, lg10_Copies, pymc3)\n",
    "        μ = self.get(name, {'μ': 0})['μ']\n",
    "        σ = self.get(name, {'σ': 1})['σ']\n",
    "        return (x_ - μ) / σ\n",
    "\n",
    "    def stdz_series(self, series: pd.Series, val_column='Value') -> float:\n",
    "        \"\"\"Apply appropriate transform to parameter in series\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        series: pd.Series\n",
    "            Series containing value to be transformed.\n",
    "            Series.name must be the name of the parameter and series must also contain a 'lg10_Copies' attribute.\n",
    "        val_column: str, default 'Value'\n",
    "            Name of series column containing value to be transformed.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            float\n",
    "        \"\"\"\n",
    "        assert series.name is not None\n",
    "        return self.stdz(str(series.name), series[val_column], series.lg10_Copies, pymc3=False)\n",
    "\n",
    "    def unstdz(self, name: str, z: float, lg10_Copies=5., pymc3=False) -> float:\n",
    "        \"\"\"Un-scales, un-centers, and un-transforms parameter\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z: float\n",
    "        name: str\n",
    "            Name of parameter\n",
    "        lg10_Copies: float, default 5.\n",
    "            Corresponding log10 concentration; only necessary for τ\n",
    "        pymc3: bool, optional\n",
    "            Whether to use pymc3's transforms\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "        \"\"\"\n",
    "        μ = self.get(name, {'μ': 0})['μ']\n",
    "        σ = self.get(name, {'σ': 1})['σ']\n",
    "        x_ = z * σ + μ\n",
    "        return self.untransform(name, x_, lg10_Copies, pymc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "def assert_in(name: str, arg, lst: Iterable):\n",
    "    \"\"\"Raises error if value not in list\"\"\"\n",
    "    if arg not in lst:\n",
    "        raise ValueError(f'{name} must be one of {lst}')\n",
    "\n",
    "\n",
    "def assert_is_subset(name: str, subset: Iterable, superset: Iterable):\n",
    "    \"\"\"Raises error if any required value not in list\"\"\"\n",
    "    l_set = set(superset)\n",
    "    r_set = set(subset)\n",
    "    if not l_set.issuperset(r_set):\n",
    "        missing = list(r_set.difference(l_set))\n",
    "        msg = f'{list_is_are(missing)} missing from {name}'\n",
    "        raise ValueError(msg)\n",
    "\n",
    "class ParameterSet:\n",
    "    \"\"\"Container for parameter estimates that enforces data integrity.\n",
    "\n",
    "    :class:`ParameterSet` is a container for a tidy dataframe (:attr:`data`) and a :class:`Standardizer`, allowing\n",
    "    simple access to standardized data (:attr:`zdata`) and wide-form views of the data (:attr:`wide`/:attr:`zwide`).\n",
    "    Ensures data integrity by enforcing a set of :attr:`required_columns` and a set of :attr:`required_parameters`.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    :class:`ParameterSet` objects are created by the :meth:`VIResult.summarize` and :meth:`MCMCResult.summarize`\n",
    "    methods, and forms the basis of the :class:`GP` class.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: pd.DataFrame\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: ParameterSet: Make required_parameters and required_descriptors optional definition at init\n",
    "    # TODO: Allow specification of stdz-able columns at init.\n",
    "    required_columns = ['Target', 'BP', 'GC', 'lg10_Copies', 'Parameter', 'Metric', 'Value']\n",
    "    required_parameters = ['τ', 'F0_lg', 'ρ', 'r', 'K', 'm']\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        self.validate(data)\n",
    "        self._data = data\n",
    "        self._stdzr = Standardizer.from_DataFrame(data)\n",
    "\n",
    "    # def _repr_html_(self):\n",
    "    #     return self.data._repr_html_()\n",
    "\n",
    "    @property\n",
    "    def stdzr(self):\n",
    "        \"\"\"Standardizer: Container for dict of mean (μ) and standard deviation (σ) for every parameter.\"\"\"\n",
    "        return self._stdzr\n",
    "\n",
    "    @stdzr.setter\n",
    "    def stdzr(self, new_stdzr: Standardizer):\n",
    "        assert isinstance(new_stdzr, Standardizer)\n",
    "        self._stdzr = new_stdzr\n",
    "\n",
    "    @property\n",
    "    def data(self) -> pd.DataFrame:\n",
    "        \"\"\"pandas.DataFrame: Underlying dataframe\"\"\"\n",
    "        return self._data\n",
    "\n",
    "    @data.setter\n",
    "    def data(self, df: pd.DataFrame):\n",
    "        \"\"\"Ensure new dataframe passes integrity checks\"\"\"\n",
    "        self.validate(df)\n",
    "        self._data = df\n",
    "        self._stdzr = Standardizer.from_DataFrame(df)\n",
    "\n",
    "    @property\n",
    "    def wide(self) -> pd.DataFrame:\n",
    "        \"\"\"Wide-form copy of data\"\"\"\n",
    "        idx_columns = [col for col in self.data.columns if col not in ['Parameter', 'Value']]\n",
    "        return (self.data\n",
    "                .pivot(index=idx_columns, columns='Parameter', values='Value')\n",
    "                .reset_index()\n",
    "                .rename_axis(columns=None)\n",
    "                )\n",
    "\n",
    "    @property\n",
    "    def zdata(self) -> pd.DataFrame:\n",
    "        \"\"\"Long-form copy of standardized data\"\"\"\n",
    "        return self.standardized\n",
    "\n",
    "    @property\n",
    "    def zwide(self) -> pd.DataFrame:\n",
    "        \"\"\"Wide-form copy of standardized data\"\"\"\n",
    "        idx_columns = [col for col in self.zdata.columns if col not in ['Parameter', 'Value']]\n",
    "        return (self.zdata\n",
    "                .pivot(index=idx_columns, columns='Parameter', values='Value')\n",
    "                .reset_index()\n",
    "                .rename_axis(columns=None)\n",
    "                )\n",
    "\n",
    "    @property\n",
    "    def standardized(self):\n",
    "        \"\"\"A copy of the instance's dataframe  with key parameters transformed and standardized.\n",
    "\n",
    "        In addition to values in the ``Value`` column corresponding to the keys in :attr:`stdzr`, columns\n",
    "        ``'BP'``, ``'GC'``, and ``'lg10_Copies'`` are also manipulated.\n",
    "        \"\"\"\n",
    "        df_ = self.data.copy()\n",
    "        df_['Value'] = (df_\n",
    "            .groupby('Parameter')\n",
    "            .apply(self.stdzr.stdz_series)\n",
    "            .reset_index()\n",
    "            .set_index('level_1')\n",
    "            .sort_index()[0])\n",
    "        for col in ['BP', 'GC', 'lg10_Copies']:\n",
    "            df_[col] = (df_[col].map(lambda x: self.stdzr.stdz(col, x)))\n",
    "        return df_\n",
    "\n",
    "    @classmethod\n",
    "    def validate(cls, df: pd.DataFrame):\n",
    "        \"\"\"Ensures provided DataFrame has all required attributes\"\"\"\n",
    "        assert isinstance(df, pd.DataFrame)\n",
    "        assert_is_subset('Columns', cls.required_columns, df.columns)\n",
    "        assert_is_subset('Parameters', cls.required_parameters, df.Parameter.unique())\n",
    "        assert 'mean' in df['Metric'].unique(), '\"Metric\" column must contain value \"mean\"'\n",
    "\n",
    "    @property\n",
    "    def valid(self):\n",
    "        \"\"\"Integrity check\"\"\"\n",
    "        return self.validate(self.data) is None\n",
    "\n",
    "    @classmethod\n",
    "    def read_pickle(cls, *args, **kwargs):\n",
    "        \"\"\"Imports from pickle file\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ParameterSet\n",
    "        \"\"\"\n",
    "        df = pd.read_pickle(*args, **kwargs)\n",
    "        return cls(df)\n",
    "\n",
    "    @classmethod\n",
    "    def read_csv(cls, *args, **kwargs):\n",
    "        \"\"\"Imports from comma delimited file\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ParameterSet\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(*args, **kwargs)\n",
    "        return cls(df)\n",
    "\n",
    "    @classmethod\n",
    "    def read_table(cls, *args, **kwargs):\n",
    "        \"\"\"Imports from generic delimited file\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ParameterSet\n",
    "        \"\"\"\n",
    "        df = pd.read_table(*args, **kwargs)\n",
    "        return cls(df)\n",
    "\n",
    "    def neaten(self):\n",
    "        \"\"\"Rearranges columns in a sensible order\"\"\"\n",
    "        other_columns = [col for col in self.data.columns if col not in self.required_columns]\n",
    "        self.data = self.data[other_columns + self.required_columns]\n",
    "\n",
    "    @classmethod\n",
    "    def from_wide(cls, wide, params=None):\n",
    "        \"\"\"Reshapes wide-form data to long-form, then instantiates class\"\"\"\n",
    "        params = cls.required_parameters if params is None else params  # Might be broken\n",
    "        meta = [col for col in wide.columns if col not in params]\n",
    "        tidy = wide.melt(id_vars=meta, value_vars=params, var_name='Parameter', value_name='Value')\n",
    "        return cls(tidy)\n",
    "\n",
    "    def save(self, filename: str):\n",
    "        \"\"\"Pickles data in wide-form to save space\"\"\"\n",
    "        self.wide.to_pickle(filename)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filename: str, params=None):\n",
    "        \"\"\"Un-pickles wide-form data, then reshapes as long-form\"\"\"\n",
    "        wide = pd.read_pickle(filename)\n",
    "        return cls.from_wide(wide, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = pl.Path(os.getcwd())\n",
    "ps_df = pd.read_pickle(path / 'data' / 'ADVI_ParameterSets_220528.pkl')\n",
    "ps_df = ps_df[(ps_df.lg10_Copies == 8)]\n",
    "ps_df = ps_df.drop(ps_df[ps_df['Experiment'].str.contains(\"JG073A\")].index)\n",
    "ps = ParameterSet.from_wide(ps_df)\n",
    "ps.data['EvaGreen'] = ((ps.data['Reporter'] == \"EVAGREEN\") | (ps.data['Reporter'] == \"SYBR\"))\n",
    "ps.data.loc[ps.data['EvaGreen'] == True, 'EvaGreen'] = 'EvaGreen'\n",
    "ps.data.loc[ps.data['EvaGreen'] == False, 'EvaGreen'] = 'Probe'\n",
    "ps.data['PrimerPairReporter'] = ps.data[['PrimerPair', 'EvaGreen']].agg('-'.join, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Get data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of surfaces: 34\n",
      "no. surfaces to be optimized: 16\n",
      "no. unique locations: 327\n",
      "total number data points: 592\n",
      "min number of repeats at a location: 1\n",
      "max number of repeats at a location: 6\n"
     ]
    }
   ],
   "source": [
    "print('no. of surfaces:',len(ps.data['PrimerPairReporter'].unique()))\n",
    "print('no. surfaces to be optimized:', len(targets['PrimerPairReporter'].unique()))\n",
    "print('no. unique locations:',len(ps.data[['BP', 'GC', 'PrimerPairReporter']].drop_duplicates()))\n",
    "print('total number data points:', len(ps.data[(ps.data['Parameter'] == 'r') & (ps.data['Metric'] == 'mean')]))\n",
    "print('min number of repeats at a location:', ps.data[(ps.data['Parameter'] == 'r') & (ps.data['Metric'] == 'mean')].value_counts(['BP', 'GC', 'PrimerPairReporter']).min())\n",
    "print('max number of repeats at a location:', ps.data[(ps.data['Parameter'] == 'r') & (ps.data['Metric'] == 'mean')].value_counts(['BP', 'GC', 'PrimerPairReporter']).max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Calculate which surfaces are in the targets list and which aren't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     FP001-RP001x-EvaGreen\n",
      "1     FP002-RP002x-EvaGreen\n",
      "2         FP005-FP001-Probe\n",
      "3        RP001x-FP002-Probe\n",
      "4        RP002x-FP005-Probe\n",
      "5      FP005-FP004-EvaGreen\n",
      "6         FP004-RP004-Probe\n",
      "8     RP002x-FP002-EvaGreen\n",
      "9      FP001-RP004-EvaGreen\n",
      "10     FP002-RP004-EvaGreen\n",
      "12        FP004-FP005-Probe\n",
      "15       RP008x-FP005-Probe\n",
      "16     FP005-FP001-EvaGreen\n",
      "18    RP002x-FP004-EvaGreen\n",
      "20    RP008x-FP001-EvaGreen\n",
      "22       FP001-RP001x-Probe\n",
      "Name: PrimerPairReporter, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(targets['PrimerPairReporter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ppr_not_in_targets = set(ps.data['PrimerPairReporter'].unique()) - set(targets['PrimerPairReporter'].unique())\n",
    "ppr_not_in_data = set(targets['PrimerPairReporter'].unique()) - set(ps.data['PrimerPairReporter'].unique())\n",
    "ppr_in_both = set(ps.data['PrimerPairReporter'].unique()) & set(targets['PrimerPairReporter'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unique_locations = ps.data[['PrimerPairReporter', 'BP', 'GC']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Print list of the surfaces which are NOT in the targets list and how many unique data locations there are on each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrimerPairReporter       \n",
       "FP004-RP004-EvaGreen         28\n",
       "FP002-RP002x-Probe           12\n",
       "FP004-RP004x-Probe           12\n",
       "FP001-RP001-Probe             9\n",
       "FP001-RP005-Probe             8\n",
       "FP004-RP004x-EvaGreen         8\n",
       "FP003-RP008-Probe             5\n",
       "FP006-RP006-Probe             5\n",
       "FP005-RP005-Probe             5\n",
       "FP002-RP002-EvaGreen          4\n",
       "FP002-RP006-Probe             4\n",
       "FP057.1.0-RP003x-Probe        3\n",
       "FP003-RP008x-EvaGreen         3\n",
       "FP003-RP008-EvaGreen          3\n",
       "FP002-RP002-Probe             3\n",
       "FP001-RP001-EvaGreen          2\n",
       "FP003-RP003-Probe             1\n",
       "FP057.1.0-RP003x-EvaGreen     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_locations[unique_locations['PrimerPairReporter'].isin(ppr_not_in_targets)].value_counts(['PrimerPairReporter'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Print list of the surfaces which are in the target list and the number of data points on each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrimerPairReporter   \n",
       "FP004-RP004-Probe        53\n",
       "FP001-RP001x-EvaGreen    24\n",
       "FP001-RP001x-Probe       20\n",
       "RP001x-FP002-Probe       19\n",
       "FP002-RP002x-EvaGreen    15\n",
       "FP005-FP001-EvaGreen     14\n",
       "FP004-FP005-Probe         8\n",
       "FP005-FP001-Probe         8\n",
       "FP005-FP004-EvaGreen      8\n",
       "RP002x-FP005-Probe        8\n",
       "RP008x-FP001-EvaGreen     8\n",
       "RP008x-FP005-Probe        8\n",
       "FP001-RP004-EvaGreen      7\n",
       "RP002x-FP004-EvaGreen     6\n",
       "FP002-RP004-EvaGreen      3\n",
       "RP002x-FP002-EvaGreen     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# amount of data of surfaces in targets:\n",
    "unique_locations[unique_locations['PrimerPairReporter'].isin(ppr_in_both)].value_counts(['PrimerPairReporter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Print list of surfaces in targets and not in targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not in targets: ['FP001-RP001-Probe' 'FP002-RP002-Probe' 'FP004-RP004-EvaGreen'\n",
      " 'FP001-RP001-EvaGreen' 'FP002-RP002-EvaGreen' 'FP001-RP005-Probe'\n",
      " 'FP005-RP005-Probe' 'FP002-RP006-Probe' 'FP006-RP006-Probe'\n",
      " 'FP003-RP008-Probe' 'FP001-RP001x-EvaGreen' 'FP002-RP002x-EvaGreen'\n",
      " 'FP004-RP004x-Probe' 'FP004-RP004x-EvaGreen' 'FP003-RP008-EvaGreen'\n",
      " 'FP003-RP008x-EvaGreen' 'FP057.1.0-RP003x-EvaGreen' 'FP003-RP003-Probe'\n",
      " 'FP057.1.0-RP003x-Probe' 'FP005-FP004-EvaGreen' 'RP002x-FP002-EvaGreen'\n",
      " 'FP001-RP004-EvaGreen' 'FP002-RP004-EvaGreen' 'FP005-FP001-EvaGreen'\n",
      " 'RP002x-FP004-EvaGreen' 'RP008x-FP001-EvaGreen']\n",
      "in targets: ['FP004-RP004-Probe' 'FP002-RP002x-Probe' 'FP001-RP001x-Probe'\n",
      " 'FP005-FP001-Probe' 'RP001x-FP002-Probe' 'RP002x-FP005-Probe'\n",
      " 'FP004-FP005-Probe' 'RP008x-FP005-Probe']\n"
     ]
    }
   ],
   "source": [
    "print('not in targets:', unique_locations[unique_locations['PrimerPairReporter']\n",
    "      .isin(ppr_not_in_targets)]['PrimerPairReporter'].unique()\n",
    ")\n",
    "\n",
    "print('in targets:',unique_locations[unique_locations['PrimerPairReporter']\n",
    "      .isin(ppr_in_both)]['PrimerPairReporter'].unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Well</th>\n",
       "      <th>Reporter</th>\n",
       "      <th>Copies</th>\n",
       "      <th>lg10_Copies</th>\n",
       "      <th>Target</th>\n",
       "      <th>FPrimer</th>\n",
       "      <th>RPrimer</th>\n",
       "      <th>PrimerPair</th>\n",
       "      <th>BP</th>\n",
       "      <th>GC</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Value</th>\n",
       "      <th>EvaGreen</th>\n",
       "      <th>PrimerPairReporter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JG034A</td>\n",
       "      <td>1</td>\n",
       "      <td>HEX</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>S044.12</td>\n",
       "      <td>FP004</td>\n",
       "      <td>RP004</td>\n",
       "      <td>FP004-RP004</td>\n",
       "      <td>88</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>mean</td>\n",
       "      <td>τ</td>\n",
       "      <td>15.672488</td>\n",
       "      <td>Probe</td>\n",
       "      <td>FP004-RP004-Probe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JG034A</td>\n",
       "      <td>1</td>\n",
       "      <td>HEX</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>S044.12</td>\n",
       "      <td>FP004</td>\n",
       "      <td>RP004</td>\n",
       "      <td>FP004-RP004</td>\n",
       "      <td>88</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>sd</td>\n",
       "      <td>τ</td>\n",
       "      <td>0.012916</td>\n",
       "      <td>Probe</td>\n",
       "      <td>FP004-RP004-Probe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JG034A</td>\n",
       "      <td>2</td>\n",
       "      <td>HEX</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>S044.12</td>\n",
       "      <td>FP004</td>\n",
       "      <td>RP004</td>\n",
       "      <td>FP004-RP004</td>\n",
       "      <td>88</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>mean</td>\n",
       "      <td>τ</td>\n",
       "      <td>15.665333</td>\n",
       "      <td>Probe</td>\n",
       "      <td>FP004-RP004-Probe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JG034A</td>\n",
       "      <td>2</td>\n",
       "      <td>HEX</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>S044.12</td>\n",
       "      <td>FP004</td>\n",
       "      <td>RP004</td>\n",
       "      <td>FP004-RP004</td>\n",
       "      <td>88</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>sd</td>\n",
       "      <td>τ</td>\n",
       "      <td>0.010921</td>\n",
       "      <td>Probe</td>\n",
       "      <td>FP004-RP004-Probe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JG034A</td>\n",
       "      <td>4</td>\n",
       "      <td>FAM</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>S044.13</td>\n",
       "      <td>FP004</td>\n",
       "      <td>RP004</td>\n",
       "      <td>FP004-RP004</td>\n",
       "      <td>88</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>mean</td>\n",
       "      <td>τ</td>\n",
       "      <td>14.257499</td>\n",
       "      <td>Probe</td>\n",
       "      <td>FP004-RP004-Probe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>JG067M</td>\n",
       "      <td>213</td>\n",
       "      <td>FAM</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>S067_b12a22_c_LVM_3</td>\n",
       "      <td>FP004</td>\n",
       "      <td>RP004</td>\n",
       "      <td>FP004-RP004</td>\n",
       "      <td>309</td>\n",
       "      <td>0.359223</td>\n",
       "      <td>sd</td>\n",
       "      <td>m</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>Probe</td>\n",
       "      <td>FP004-RP004-Probe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>JG067M</td>\n",
       "      <td>214</td>\n",
       "      <td>HEX</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>S067_b12a22_d_LVM_3</td>\n",
       "      <td>FP004</td>\n",
       "      <td>FP005</td>\n",
       "      <td>FP004-FP005</td>\n",
       "      <td>476</td>\n",
       "      <td>0.348739</td>\n",
       "      <td>mean</td>\n",
       "      <td>m</td>\n",
       "      <td>0.009874</td>\n",
       "      <td>Probe</td>\n",
       "      <td>FP004-FP005-Probe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>JG067M</td>\n",
       "      <td>214</td>\n",
       "      <td>HEX</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>S067_b12a22_d_LVM_3</td>\n",
       "      <td>FP004</td>\n",
       "      <td>FP005</td>\n",
       "      <td>FP004-FP005</td>\n",
       "      <td>476</td>\n",
       "      <td>0.348739</td>\n",
       "      <td>sd</td>\n",
       "      <td>m</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>Probe</td>\n",
       "      <td>FP004-FP005-Probe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7102</th>\n",
       "      <td>JG067M</td>\n",
       "      <td>215</td>\n",
       "      <td>EVAGREEN</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>S067_b12a22_α_LVM_3</td>\n",
       "      <td>FP001</td>\n",
       "      <td>RP001x</td>\n",
       "      <td>FP001-RP001x</td>\n",
       "      <td>49</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>mean</td>\n",
       "      <td>m</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>EvaGreen</td>\n",
       "      <td>FP001-RP001x-EvaGreen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7103</th>\n",
       "      <td>JG067M</td>\n",
       "      <td>215</td>\n",
       "      <td>EVAGREEN</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>S067_b12a22_α_LVM_3</td>\n",
       "      <td>FP001</td>\n",
       "      <td>RP001x</td>\n",
       "      <td>FP001-RP001x</td>\n",
       "      <td>49</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>sd</td>\n",
       "      <td>m</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>EvaGreen</td>\n",
       "      <td>FP001-RP001x-EvaGreen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7104 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Experiment  Well  Reporter       Copies  lg10_Copies  \\\n",
       "0        JG034A     1       HEX  100000000.0          8.0   \n",
       "1        JG034A     1       HEX  100000000.0          8.0   \n",
       "2        JG034A     2       HEX  100000000.0          8.0   \n",
       "3        JG034A     2       HEX  100000000.0          8.0   \n",
       "4        JG034A     4       FAM  100000000.0          8.0   \n",
       "...         ...   ...       ...          ...          ...   \n",
       "7099     JG067M   213       FAM  100000000.0          8.0   \n",
       "7100     JG067M   214       HEX  100000000.0          8.0   \n",
       "7101     JG067M   214       HEX  100000000.0          8.0   \n",
       "7102     JG067M   215  EVAGREEN  100000000.0          8.0   \n",
       "7103     JG067M   215  EVAGREEN  100000000.0          8.0   \n",
       "\n",
       "                   Target FPrimer RPrimer    PrimerPair   BP        GC Metric  \\\n",
       "0                 S044.12   FP004   RP004   FP004-RP004   88  0.431818   mean   \n",
       "1                 S044.12   FP004   RP004   FP004-RP004   88  0.431818     sd   \n",
       "2                 S044.12   FP004   RP004   FP004-RP004   88  0.431818   mean   \n",
       "3                 S044.12   FP004   RP004   FP004-RP004   88  0.431818     sd   \n",
       "4                 S044.13   FP004   RP004   FP004-RP004   88  0.431818   mean   \n",
       "...                   ...     ...     ...           ...  ...       ...    ...   \n",
       "7099  S067_b12a22_c_LVM_3   FP004   RP004   FP004-RP004  309  0.359223     sd   \n",
       "7100  S067_b12a22_d_LVM_3   FP004   FP005   FP004-FP005  476  0.348739   mean   \n",
       "7101  S067_b12a22_d_LVM_3   FP004   FP005   FP004-FP005  476  0.348739     sd   \n",
       "7102  S067_b12a22_α_LVM_3   FP001  RP001x  FP001-RP001x   49  0.510204   mean   \n",
       "7103  S067_b12a22_α_LVM_3   FP001  RP001x  FP001-RP001x   49  0.510204     sd   \n",
       "\n",
       "     Parameter      Value  EvaGreen     PrimerPairReporter  \n",
       "0            τ  15.672488     Probe      FP004-RP004-Probe  \n",
       "1            τ   0.012916     Probe      FP004-RP004-Probe  \n",
       "2            τ  15.665333     Probe      FP004-RP004-Probe  \n",
       "3            τ   0.010921     Probe      FP004-RP004-Probe  \n",
       "4            τ  14.257499     Probe      FP004-RP004-Probe  \n",
       "...        ...        ...       ...                    ...  \n",
       "7099         m   0.000254     Probe      FP004-RP004-Probe  \n",
       "7100         m   0.009874     Probe      FP004-FP005-Probe  \n",
       "7101         m   0.000283     Probe      FP004-FP005-Probe  \n",
       "7102         m   0.000274  EvaGreen  FP001-RP001x-EvaGreen  \n",
       "7103         m   0.000162  EvaGreen  FP001-RP001x-EvaGreen  \n",
       "\n",
       "[7104 rows x 16 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrimerPairReporter       \n",
       "FP004-RP004-EvaGreen         72\n",
       "FP002-RP002x-Probe           42\n",
       "FP001-RP001-Probe            26\n",
       "FP004-RP004x-Probe           24\n",
       "FP001-RP005-Probe            16\n",
       "FP004-RP004x-EvaGreen        16\n",
       "FP003-RP008-Probe            10\n",
       "FP002-RP002-EvaGreen         10\n",
       "FP006-RP006-Probe            10\n",
       "FP002-RP006-Probe            10\n",
       "FP005-RP005-Probe            10\n",
       "FP001-RP001-EvaGreen          6\n",
       "FP003-RP008x-EvaGreen         6\n",
       "FP002-RP002-Probe             6\n",
       "FP057.1.0-RP003x-Probe        6\n",
       "FP003-RP008-EvaGreen          5\n",
       "FP003-RP003-Probe             3\n",
       "FP057.1.0-RP003x-EvaGreen     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_only = ps.data[(ps.data['Parameter'] == 'r') & (ps.data['Metric'] == 'mean')]\n",
    "\n",
    "all_data = r_only[['PrimerPairReporter', 'BP', 'GC']]\n",
    "\n",
    "all_data[all_data['PrimerPairReporter'].isin(ppr_not_in_targets)].value_counts(['PrimerPairReporter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrimerPairReporter   \n",
       "FP004-RP004-Probe        87\n",
       "FP001-RP001x-EvaGreen    55\n",
       "FP002-RP002x-EvaGreen    38\n",
       "FP001-RP001x-Probe       32\n",
       "RP001x-FP002-Probe       20\n",
       "FP005-FP001-EvaGreen     14\n",
       "FP004-FP005-Probe         8\n",
       "FP005-FP001-Probe         8\n",
       "FP005-FP004-EvaGreen      8\n",
       "RP002x-FP005-Probe        8\n",
       "RP008x-FP001-EvaGreen     8\n",
       "RP008x-FP005-Probe        8\n",
       "FP001-RP004-EvaGreen      7\n",
       "RP002x-FP004-EvaGreen     6\n",
       "FP002-RP004-EvaGreen      3\n",
       "RP002x-FP002-EvaGreen     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[all_data['PrimerPairReporter'].isin(ppr_in_both)].value_counts(['PrimerPairReporter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Print the target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(targets[['PrimerPairReporter', 'Target Rate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#In targets:\n",
    "\n",
    "in_targ = ['FP004-RP004-Probe', 'FP001-RP001x-EvaGreen', 'FP002-RP002x-EvaGreen',\n",
    " 'FP001-RP001x-Probe', 'FP005-FP001-Probe', 'RP001x-FP002-Probe',\n",
    " 'RP002x-FP005-Probe', 'FP005-FP004-EvaGreen' ,'RP002x-FP002-EvaGreen',\n",
    " 'FP001-RP004-EvaGreen', 'FP002-RP004-EvaGreen', 'FP004-FP005-Probe',\n",
    " 'RP008x-FP005-Probe', 'FP005-FP001-EvaGreen', 'RP002x-FP004-EvaGreen',\n",
    " 'RP008x-FP001-EvaGreen']\n",
    "\n",
    "\n",
    "#Not in targets:\n",
    "out_targ = ['FP001-RP001-Probe', 'FP002-RP002-Probe', 'FP004-RP004-EvaGreen',\n",
    " 'FP001-RP001-EvaGreen', 'FP002-RP002-EvaGreen', 'FP001-RP005-Probe',\n",
    " 'FP005-RP005-Probe', 'FP002-RP006-Probe', 'FP006-RP006-Probe',\n",
    " 'FP003-RP008-Probe', 'FP002-RP002x-Probe', 'FP004-RP004x-Probe',\n",
    " 'FP004-RP004x-EvaGreen', 'FP003-RP008-EvaGreen', 'FP003-RP008x-EvaGreen',\n",
    " 'FP057.1.0-RP003x-EvaGreen', 'FP003-RP003-Probe', 'FP057.1.0-RP003x-Probe']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "surfs1 = ['FP001-RP001-Probe', 'FP002-RP002-Probe', 'FP004-RP004-EvaGreen',\n",
    "                 'FP001-RP001-EvaGreen', 'FP002-RP002-EvaGreen', 'FP001-RP005-Probe',\n",
    "                 'FP005-RP005-Probe', 'FP002-RP006-Probe', 'FP006-RP006-Probe',\n",
    "                 'FP003-RP008-Probe', 'FP002-RP002x-Probe', 'FP004-RP004x-Probe',\n",
    "                 'FP004-RP004x-EvaGreen', 'FP003-RP008-EvaGreen', 'FP003-RP008x-EvaGreen',\n",
    "                 'FP057.1.0-RP003x-EvaGreen', 'FP003-RP003-Probe', 'FP057.1.0-RP003x-Probe',\n",
    "                 'FP001-RP001x-EvaGreen', 'FP004-RP004-Probe',\n",
    "                 'FP001-RP001x-Probe', 'FP005-FP001-Probe', 'RP001x-FP002-Probe',\n",
    "                 'RP002x-FP005-Probe', 'FP005-FP004-EvaGreen', 'RP002x-FP002-EvaGreen',\n",
    "                 'FP001-RP004-EvaGreen', 'FP002-RP004-EvaGreen', 'FP004-FP005-Probe',\n",
    "                 'RP008x-FP005-Probe', 'FP005-FP001-EvaGreen', 'RP002x-FP004-EvaGreen',\n",
    "                 'RP008x-FP001-EvaGreen', 'FP002-RP002x-EvaGreen']\n",
    "\n",
    "all_surfaces = ['FP004-RP004-Probe', 'FP001-RP001x-EvaGreen', 'FP002-RP002x-EvaGreen',\n",
    "                     'FP001-RP001x-Probe', 'FP005-FP001-Probe', 'RP001x-FP002-Probe',\n",
    "                     'RP002x-FP005-Probe', 'FP005-FP004-EvaGreen', 'RP002x-FP002-EvaGreen',\n",
    "                     'FP001-RP004-EvaGreen', 'FP002-RP004-EvaGreen', 'FP004-FP005-Probe',\n",
    "                     'RP008x-FP005-Probe', 'FP005-FP001-EvaGreen', 'RP002x-FP004-EvaGreen',\n",
    "                     'RP008x-FP001-EvaGreen', 'FP001-RP001-Probe', 'FP002-RP002-Probe', 'FP004-RP004-EvaGreen',\n",
    "                     'FP001-RP001-EvaGreen', 'FP002-RP002-EvaGreen', 'FP001-RP005-Probe',\n",
    "                     'FP005-RP005-Probe', 'FP002-RP006-Probe', 'FP006-RP006-Probe',\n",
    "                     'FP003-RP008-Probe', 'FP002-RP002x-Probe', 'FP004-RP004x-Probe',\n",
    "                     'FP004-RP004x-EvaGreen', 'FP003-RP008-EvaGreen', 'FP003-RP008x-EvaGreen',\n",
    "                     'FP057.1.0-RP003x-EvaGreen', 'FP003-RP003-Probe', 'FP057.1.0-RP003x-Probe']\n",
    "\n",
    "out_targ = ['FP001-RP001-Probe', 'FP002-RP002-Probe', 'FP004-RP004-EvaGreen',\n",
    "                'FP001-RP001-EvaGreen', 'FP002-RP002-EvaGreen', 'FP001-RP005-Probe',\n",
    "                'FP005-RP005-Probe', 'FP002-RP006-Probe', 'FP006-RP006-Probe',\n",
    "                'FP003-RP008-Probe', 'FP002-RP002x-Probe', 'FP004-RP004x-Probe',\n",
    "                'FP004-RP004x-EvaGreen', 'FP003-RP008-EvaGreen', 'FP003-RP008x-EvaGreen',\n",
    "                'FP057.1.0-RP003x-EvaGreen', 'FP003-RP003-Probe', 'FP057.1.0-RP003x-Probe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(set(all_surfaces) - set(out_targ)))\n",
    "len(surfs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from candas.learn import parray\n",
    "\n",
    "unique_locations = ps.data[['BP', 'GC', 'PrimerPairReporter']].drop_duplicates()\n",
    "temp_parray = parray(**{'BP': unique_locations['BP'], 'GC': unique_locations['GC'],\n",
    "                        'PrimerPairReporter':unique_locations['PrimerPairReporter']}, stdzr=ps.stdzr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "unique_locations['centre dist'] = np.sqrt(\n",
    "                (temp_parray['BP'].z.values() - 0) ** 2\n",
    "                + (temp_parray['GC'].z.values() - 0) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unique_locations['BP_z'] = temp_parray['BP'].z.values()\n",
    "unique_locations['GC_z'] = temp_parray['GC'].z.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(unique_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sorted_data = pd.merge(ps.data[(ps.data['Parameter'] == 'r') & (ps.data['Metric'] == 'mean')],\n",
    "                                   unique_locations, on=['BP', 'GC', 'PrimerPairReporter'],\n",
    "                                   how='left').sort_values(by='centre dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, target in targets.iterrows():\n",
    "    ppr = target['PrimerPairReporter']\n",
    "    targ = target['Target Rate']\n",
    "    temp_df = ps.data[(ps.data['PrimerPairReporter'] == ppr) & (ps.data['Parameter'] == 'r') & (ps.data['Metric'] == 'mean')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
